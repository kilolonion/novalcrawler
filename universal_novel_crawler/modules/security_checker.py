"""
å®‰å…¨æ£€æŸ¥æ¨¡å— - æ£€æµ‹å’Œé˜»æ­¢è®¿é—®æ•æ„Ÿæˆ–è¢«ç¦æ­¢çš„ç½‘ç«™
Security Checker Module - Detect and block access to sensitive or prohibited websites
"""

import re
import tldextract
from typing import List, Set, Tuple, Optional
from urllib.parse import urlparse

from ..utils import safe_print


class SecurityChecker:
    """å®‰å…¨æ£€æŸ¥å™¨ - æ£€æµ‹æ•æ„Ÿç½‘ç«™å’Œä¸å½“ä½¿ç”¨"""
    
    def __init__(self):
        # æ•æ„ŸåŸŸååç¼€é»‘åå•
        self.SENSITIVE_DOMAINS = {
            # æ”¿åºœæœºå…³
            '.gov.cn', '.gov', '.government.cn',
            # å†›äº‹æœºæ„
            '.mil.cn', '.mil', '.army.cn', '.navy.cn', '.airforce.cn',
            # å…¬å®‰ç³»ç»Ÿ
            '.police.cn', '.gaj.', '.mps.gov.cn',
            # å¸æ³•ç³»ç»Ÿ
            '.court.gov.cn', '.procuratorate.gov.cn', '.justice.gov.cn',
            # å›½å®¶å®‰å…¨
            '.mss.gov.cn', '.state-security.cn',
            # æ¶‰å¯†æœºæ„
            '.classified.', '.secret.', '.confidential.',
        }
        
        # æ•æ„Ÿå…³é”®è¯
        self.SENSITIVE_KEYWORDS = {
            # æ”¿åºœç›¸å…³
            'government', 'æ”¿åºœ', 'äººæ°‘æ”¿åºœ', 'å¸‚æ”¿åºœ', 'çœæ”¿åºœ', 'å¿æ”¿åºœ',
            'gongan', 'å…¬å®‰', 'police', 'è­¦å¯Ÿ', 'æ´¾å‡ºæ‰€', 'æ²»å®‰',
            'court', 'æ³•é™¢', 'æ£€å¯Ÿé™¢', 'å¸æ³•',
            'military', 'å†›äº‹', 'éƒ¨é˜Ÿ', 'å†›åŒº', 'æˆ˜åŒº', 'å†›å§”',
            # é‡‘èæœºæ„
            'bank', 'é“¶è¡Œ', 'securities', 'è¯åˆ¸', 'insurance', 'ä¿é™©',
            'finance', 'é‡‘è', 'monetary', 'è´§å¸', 'central-bank', 'å¤®è¡Œ',
            # åŒ»ç–—æœºæ„  
            'hospital', 'åŒ»é™¢', 'medical', 'åŒ»ç–—', 'health', 'å«ç”Ÿ',
            'patient', 'ç—…äºº', 'ç—…å†',
            # æ•™è‚²æœºæ„
            'education', 'æ•™è‚²', 'school', 'å­¦æ ¡', 'university', 'å¤§å­¦',
            'student', 'å­¦ç”Ÿ', 'å­¦ç±',
            # ç”µä¿¡è¿è¥å•†
            'telecom', 'ç”µä¿¡', 'mobile', 'ç§»åŠ¨', 'unicom', 'è”é€š',
            'communication', 'é€šä¿¡',
        }
        
        # ç‰¹å®šæ•æ„Ÿç½‘ç«™åŸŸå
        self.BLOCKED_DOMAINS = {
            # æ”¿åºœç½‘ç«™ç¤ºä¾‹
            'www.gov.cn', 'www.12306.cn', 'www.tax.gov.cn',
            # é‡‘èç½‘ç«™ç¤ºä¾‹  
            'www.pboc.gov.cn', 'www.csrc.gov.cn', 'www.cbirc.gov.cn',
            # å†›äº‹ç½‘ç«™ç¤ºä¾‹
            'www.mod.gov.cn', 'www.81.cn',
            # å…¶ä»–æ•æ„Ÿç½‘ç«™
            'www.miit.gov.cn', 'www.mps.gov.cn',
        }
        
        # åˆæ³•çš„å°è¯´ç½‘ç«™ç™½åå•ï¼ˆå…è®¸è®¿é—®çš„åŸŸåæ¨¡å¼ï¼‰
        self.NOVEL_SITE_PATTERNS = {
            r'.*xiaoshuo.*',  # åŒ…å«"å°è¯´"
            r'.*novel.*',     # åŒ…å«"novel"
            r'.*book.*',      # åŒ…å«"book"
            r'.*read.*',      # åŒ…å«"read" 
            r'.*story.*',     # åŒ…å«"story"
            r'.*fiction.*',   # åŒ…å«"fiction"
            r'.*literature.*', # åŒ…å«"literature"
            r'.*biquge.*',    # ç¬”è¶£é˜ç³»åˆ—
            r'.*qidian.*',    # èµ·ç‚¹ï¼ˆå·²ç§»é™¤ä½†ä¿ç•™æ£€æµ‹ï¼‰
            r'.*zongheng.*',  # çºµæ¨ª
            r'.*17k.*',       # 17K
            r'.*jjwxc.*',     # æ™‹æ±Ÿ
            r'localhost.*',   # æœ¬åœ°æµ‹è¯•
            r'127\.0\.0\.1.*', # æœ¬åœ°IP
        }
    
    def is_sensitive_site(self, url: str) -> Tuple[bool, str]:
        """
        æ£€æŸ¥URLæ˜¯å¦ä¸ºæ•æ„Ÿç½‘ç«™
        è¿”å›: (æ˜¯å¦æ•æ„Ÿ, åŸå› è¯´æ˜)
        """
        if not url:
            return False, ""
            
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            full_url = url.lower()
            
            # 1. æ£€æŸ¥åŸŸååç¼€
            for sensitive_suffix in self.SENSITIVE_DOMAINS:
                if domain.endswith(sensitive_suffix):
                    return True, f"æ£€æµ‹åˆ°æ•æ„ŸåŸŸååç¼€: {sensitive_suffix}"
            
            # 2. æ£€æŸ¥ç‰¹å®šè¢«ç¦åŸŸå
            if domain in self.BLOCKED_DOMAINS:
                return True, f"åŸŸååœ¨é»‘åå•ä¸­: {domain}"
            
            # 3. æ£€æŸ¥æ•æ„Ÿå…³é”®è¯
            for keyword in self.SENSITIVE_KEYWORDS:
                if keyword in domain or keyword in full_url:
                    return True, f"æ£€æµ‹åˆ°æ•æ„Ÿå…³é”®è¯: {keyword}"
            
            # 4. ä½¿ç”¨tldextractè¿›ä¸€æ­¥åˆ†æ
            try:
                extracted = tldextract.extract(url)
                if extracted.suffix in ['.gov', '.mil', '.edu'] and extracted.domain not in ['github', 'gitlab']:
                    return True, f"æ£€æµ‹åˆ°æ•æ„Ÿé¡¶çº§åŸŸå: .{extracted.suffix}"
            except:
                pass
                
            return False, ""
            
        except Exception as e:
            safe_print(f"âš ï¸ URLå®‰å…¨æ£€æŸ¥æ—¶å‡ºé”™: {e}")
            return False, ""
    
    def is_likely_novel_site(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦å¯èƒ½æ˜¯å°è¯´ç½‘ç«™"""
        if not url:
            return False
            
        domain = urlparse(url).netloc.lower()
        
        for pattern in self.NOVEL_SITE_PATTERNS:
            if re.match(pattern, domain):
                return True
                
        return False
    
    def check_url_safety(self, url: str) -> Tuple[bool, str]:
        """
        ç»¼åˆå®‰å…¨æ£€æŸ¥
        è¿”å›: (æ˜¯å¦å®‰å…¨å¯è®¿é—®, æç¤ºä¿¡æ¯)
        """
        if not url:
            return False, "URLä¸ºç©º"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ•æ„Ÿç½‘ç«™
        is_sensitive, reason = self.is_sensitive_site(url)
        if is_sensitive:
            return False, f"ğŸš« æ‹’ç»è®¿é—®æ•æ„Ÿç½‘ç«™: {reason}"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç–‘ä¼¼å°è¯´ç½‘ç«™
        if self.is_likely_novel_site(url):
            return True, "âœ… æ£€æµ‹åˆ°ç–‘ä¼¼å°è¯´ç½‘ç«™ï¼Œå…è®¸è®¿é—®"
        
        # å¯¹äºå…¶ä»–ç½‘ç«™ç»™å‡ºè­¦å‘Šä½†å…è®¸è®¿é—®
        return True, "âš ï¸ æœªçŸ¥ç½‘ç«™ç±»å‹ï¼Œè¯·ç¡®ä¿ä»…ç”¨äºåˆæ³•çš„å°è¯´å†…å®¹çˆ¬å–"
    
    def validate_crawl_request(self, url: str, force_check: bool = True) -> bool:
        """
        éªŒè¯çˆ¬å–è¯·æ±‚çš„åˆæ³•æ€§
        
        Args:
            url: è¦çˆ¬å–çš„URL
            force_check: æ˜¯å¦å¼ºåˆ¶æ£€æŸ¥ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            bool: æ˜¯å¦å…è®¸çˆ¬å–
        """
        if not force_check:
            return True
            
        is_safe, message = self.check_url_safety(url)
        
        if not is_safe:
            safe_print(f"âŒ {message}")
            safe_print("ğŸ“– è¯·ä½¿ç”¨æœ¬å·¥å…·çˆ¬å–åˆæ³•çš„å°è¯´ç½‘ç«™å†…å®¹")
            safe_print("ğŸ“‹ è¯¦ç»†è§„åˆ™è¯·æŸ¥çœ‹ DISCLAIMER.md å…è´£å£°æ˜")
            return False
        else:
            if "ç–‘ä¼¼å°è¯´ç½‘ç«™" not in message:
                safe_print(f"âš ï¸ {message}")
            return True
    
    def get_security_report(self, url: str) -> dict:
        """ç”Ÿæˆå®‰å…¨æ£€æŸ¥æŠ¥å‘Š"""
        is_sensitive, sensitive_reason = self.is_sensitive_site(url)
        is_novel = self.is_likely_novel_site(url)
        is_safe, safety_message = self.check_url_safety(url)
        
        return {
            'url': url,
            'is_sensitive': is_sensitive,
            'sensitive_reason': sensitive_reason,
            'is_likely_novel_site': is_novel,
            'is_safe': is_safe,
            'safety_message': safety_message,
            'domain': urlparse(url).netloc,
        }


def get_security_checker() -> SecurityChecker:
    """è·å–å®‰å…¨æ£€æŸ¥å™¨å®ä¾‹"""
    return SecurityChecker() 